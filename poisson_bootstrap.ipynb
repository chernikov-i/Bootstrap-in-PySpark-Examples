{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011ddcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window, functions as F, types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae74820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/23 12:10:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYSPARK_PYTHON']= sys.executable\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local[1]\")\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7197601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+------+----------+--------------------+\n",
      "|camp_id|control_group_flg|revenue|margin|conversion|             user_id|\n",
      "+-------+-----------------+-------+------+----------+--------------------+\n",
      "|ED_3755|                0|   4.77|   5.3|         1|6f9be979ec9f4aba9...|\n",
      "|ED_3755|                0|   7.53|  8.12|         1|6a0a4bdd10e670717...|\n",
      "|ED_3755|                0|  12.33|  5.24|         1|2b96123b22c810b53...|\n",
      "|ED_3755|                0|   5.44|  4.32|         1|06d37e5b5d6c45a9a...|\n",
      "|ED_3755|                0|    0.0|   0.0|         0|86fcb416dd0d2b9e7...|\n",
      "+-------+-----------------+-------+------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField('camp_id', T.StringType()),\n",
    "    T.StructField('control_group_flg', T.ShortType()),\n",
    "    T.StructField('revenue', T.DoubleType()),\n",
    "    T.StructField('margin', T.DoubleType()),\n",
    "    T.StructField('conversion', T.ShortType()),\n",
    "    T.StructField('user_id', T.StringType()),\n",
    "])\n",
    "\n",
    "statistics_df = spark.createDataFrame(pd.read_csv('data_sample.csv'))\n",
    "statistics_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce1269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список ключевых столбцов групп\n",
    "KEY_COLS = ['camp_id', 'control_group_flg']\n",
    "# Список метрик, по которым считаем статистику\n",
    "STATISTICS_COLS = ['revenue', 'margin', 'conversion']\n",
    "# Количество бутстрап операций\n",
    "BS_ITERS = 10000\n",
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352e9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf для создания массива количества появлений строки в каждой итерации\n",
    "pois_udf = F.udf(lambda size: np.random.poisson(1, size).tolist(), \n",
    "                 T.ArrayType(T.IntegerType()))\n",
    "\n",
    "result_df = (\n",
    "    statistics_df\n",
    "    .withColumn('iter_cnt', F.lit(BS_ITERS))\n",
    "    # создаем массив с количеством вхождений строки в каждую итерацию\n",
    "    .withColumn('poisson_array', pois_udf(F.col('iter_cnt')))\n",
    "    # делаем posexplode, сохраняя порядковый номер итерации и количество вхождений\n",
    "    .select(\n",
    "        KEY_COLS \n",
    "        + [F.posexplode('poisson_array').alias('iter_num', 'poisson')] \n",
    "        + STATISTICS_COLS\n",
    "    )\n",
    "    # Убираем лишние строки, которые не участвуют в итерации бутстрапа\n",
    "    .filter(F.col('poisson') != 0)\n",
    "    # Группируем по ключевым полям и номеру итерации\n",
    "    .groupBy(KEY_COLS  + ['iter_num'])\n",
    "    # Считаем сумму метрик и количество клиентов в каждой итерации\n",
    "    .agg(*(\n",
    "        [F.sum(F.col('poisson') * F.col(stat_col)).alias(stat_col) \n",
    "         for stat_col in STATISTICS_COLS] \n",
    "        + \n",
    "        [F.sum(F.col('poisson')).alias('total_cnt')]\n",
    "    ))\n",
    ")\n",
    "\n",
    "# Рассчитываем значение средних для каждой итерации\n",
    "for stat_col in STATISTICS_COLS:\n",
    "    result_df = (result_df\n",
    "                 .withColumn(stat_col, F.col(stat_col) / F.col('total_cnt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f881afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camp_id</th>\n",
       "      <th>revenue</th>\n",
       "      <th>margin</th>\n",
       "      <th>conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ED_3755</td>\n",
       "      <td>[0.16715380990486672, 1.2306713983908648]</td>\n",
       "      <td>[-0.8067694136025351, 0.2941336974675275]</td>\n",
       "      <td>[0.011820438005005308, 0.06960119682338302]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   camp_id                                    revenue  \\\n",
       "0  ED_3755  [0.16715380990486672, 1.2306713983908648]   \n",
       "\n",
       "                                      margin  \\\n",
       "0  [-0.8067694136025351, 0.2941336974675275]   \n",
       "\n",
       "                                    conversion  \n",
       "0  [0.011820438005005308, 0.06960119682338302]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраняем результат и приводим к единому виду с остальными тетрадками\n",
    "result = result_df.toPandas()\n",
    "# Минусуем метрики контрольной группы, чтобы сложить можно было для получения разницы\n",
    "result.loc[result['control_group_flg'] == 1, STATISTICS_COLS] *= -1\n",
    "# Можно собирать и сразу в pyspark\n",
    "result = (\n",
    "    result\n",
    "    .groupby(['camp_id', 'iter_num'], as_index=False).sum()\n",
    "    .groupby('camp_id', as_index=False)[STATISTICS_COLS].quantile([ALPHA/2, 1-ALPHA/2])\n",
    "    .groupby('camp_id', as_index=False).agg(list)\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91015e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b2c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
